{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction d'un auto-encodeur avec Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P style=\"text-align:center\"><img src=\"https://blog.keras.io/img/ae/autoencoder_schema.jpg\" style=\"float:center; display: inline\" alt=\"schema\"/></P>\n",
    "*Architecture d'un autoencoder*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objectif\n",
    "#### i. Présentatation générale\n",
    "\n",
    "L'objectif de ce TP est de construire un auto-encodeur. Un auto-encodeur est un algorithme de compression des données dont les fonctions de compression et décompression reposent sur 3 caratéristiques principales :\n",
    "\n",
    "* il est **spécifique aux données**, c'est-à-dire qu'il n'est construit que pour un seul type de donnée à la fois, ainsi il ne sera capable de traiter que des données similaires à celles sur lesquelles il s'est entrainé. Cela s'explique de par le fait que les features qu'il aura appris seront propres au type de données qu'il aura traité. \n",
    "\n",
    "* il est **à perte**, c'est-à-dire que comme tout compresseur, il fait perdre de leur qualité aux données en sortie par rapport à celles en entrée.\n",
    "* il est **à apprentissage** : c'est un réseau de neurones donc il a besoin d'exemples de données pour fonctionner.\n",
    "\n",
    "\n",
    "Pour construire un tel algorithme, il nous faut 3 éléments précis : une **fonction de codage**, une **fonction de décodage** et une **fonction de distance ou fonction de \"loss\"** (cette dernière permet de calculer la quantité d'information perdue lors de la compression).\n",
    "\n",
    "Les fonctions de **codage** et de ** décodage** seront des réseaux de neurones différentiable par rapport à la fonction de perte, de manière à ce que les paramètres du codage/décodage puissent être optimisés de sorte que l'on minimise la perte lors de la phase de reconstruction.  \n",
    "\n",
    "Ce type d'auto-encodeur est très peu utilisé aujourd'hui principalement à cause de sa spécificité aux données.Mais, l'auto-encoding a été longtemps considéré comme un moyen potentiel de résoudre le problème de l'apprentissage non-supervisé ie l'apprentissage sans labels.\n",
    "\n",
    "L'auto-encoding n'est pas une technique de supervisation d'apprentissage mais plutôt une auto-supervisation (car gènère la valeur souhaitée (target) à partir de l'entrée qui lui a été fournie).\n",
    "\n",
    "Dans le but de permettre à l'auto-encoder d'apprendre des features intéressantes, on doit lui fournir d'intéressantes target and loss fonctions. \n",
    "\n",
    "#### ii. Sum-up\n",
    "\n",
    "Un **autoencoder** est donc un **réseau de neurones** dont le but est de faire correspondre  ces entrées à ces sorties (sorte de recopie). \n",
    "\n",
    "Cela va se faire dans un premier temps par la compression de l'entrée dans une représentation en **espace latent** (latent space est un espace permettant de capturer les features principales des données que l'on traite). Puis dans un second temps on va reconstruire la sortie à partir de la représentation obtenue (représentation dans l'espace latent). \n",
    "\n",
    "Comme l'indique le schéma ci-dessus l'autoencoder est composé de deux parties : \n",
    "\n",
    "* **Encoder** qui compresse l'entrée dans l'espace latent. \n",
    "* **Decoder** qui reconstruit l'entrée à partir de la représentation dans l'espace latent.  \n",
    "\n",
    "Afin de faire en sorte que l'utilité d'un autoencoder ne soit pas réduite à une simple tâche de recopie on peut limité la taille de la **\" compressed representation\" ** de sorte qu'elle soit de taille plus petite que celle de l'entrée ainsi cette représentation force l'autoencoder à apprendre que les caractéristiques pertinentes des données. \n",
    "\n",
    "\n",
    "\n",
    "## 2. Mise en pratique\n",
    "\n",
    "### i. Construction Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/insa/anaconda/envs/GPU/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif ici est de compresser l'image, dont la taille de départ est de 784. Le facteur de compression est de 24,5 : on obtient donc comme taille finale 784/24,5 = 32. Ainsi, la première étape est de donner au réseau de neurône l'image en entrée, en spécifiant sa taille, et d'utiliser la **fonction de codage** sur cette image en entrée. Pour le moment, aucune opération n'est réalisée, on a définie le graphe. On rappelle ici que la fonction **relu (Unité de Rectification Linéaire)** est définie de la façon suivante :\n",
    "\n",
    "$$relu(x) = max(0,x)$$\n",
    "\n",
    "et la fonction sigmoid est quant-à-elle définie par :\n",
    "\n",
    "$$sigmoid(x) = \\frac{1}{1+\\text{e}^x}$$\n",
    "\n",
    "à valeurs dans $[0,1]$. Ainsi, on utilise pour décoder la fonction **sigmoid** afin d'obtenir des valeurs de probabilités."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Construction encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoder** est un modèle incluant toutes les couches impliqué dans le calcul de **encoded** à partir de **input_img**.\n",
    "\n",
    "### iii. Construction decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1] \n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**decoder** est un modèle incluant toutes les couches impliqué dans le calcul de **decoded** à partir de **encoded_input**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explication des 2 codes précédents???**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. Importation et traitement des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**x_train** est à trois dimmensions (on a 60000 images chacune de taile 28x28). Dans la suite on normalise toutes les valeurs et on applatit les valeurs de chaque image de sorte que chaque image soit représenté par un vecteur de taille 784.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255. # Pour normaliser toutes les valeurs \n",
    "x_test = x_test.astype('float32') / 255.# Pour normaliser toutes les valeurs \n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v. Phase d'apprentissage de l'autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.3646 - val_loss: 0.2710\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2633 - val_loss: 0.2529\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2433 - val_loss: 0.2314\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2231 - val_loss: 0.2125\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2067 - val_loss: 0.1985\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1950 - val_loss: 0.1890\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1867 - val_loss: 0.1817\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1801 - val_loss: 0.1757\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1746 - val_loss: 0.1706\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1697 - val_loss: 0.1660\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1653 - val_loss: 0.1618\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1614 - val_loss: 0.1580\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1577 - val_loss: 0.1545\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1543 - val_loss: 0.1512\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1511 - val_loss: 0.1482\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1481 - val_loss: 0.1452\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1453 - val_loss: 0.1424\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1427 - val_loss: 0.1398\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1402 - val_loss: 0.1374\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1378 - val_loss: 0.1351\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1355 - val_loss: 0.1329\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1334 - val_loss: 0.1308\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1313 - val_loss: 0.1288\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1294 - val_loss: 0.1268\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1275 - val_loss: 0.1250\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1257 - val_loss: 0.1233\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1240 - val_loss: 0.1217\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1224 - val_loss: 0.1201\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1210 - val_loss: 0.1187\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1196 - val_loss: 0.1174\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1183 - val_loss: 0.1161\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1171 - val_loss: 0.1149\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1160 - val_loss: 0.1139\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1150 - val_loss: 0.1129\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1140 - val_loss: 0.1119\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1131 - val_loss: 0.1111\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1123 - val_loss: 0.1103\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1115 - val_loss: 0.1096\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1108 - val_loss: 0.1089\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1102 - val_loss: 0.1083\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1096 - val_loss: 0.1077\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1090 - val_loss: 0.1072\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1085 - val_loss: 0.1066\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1080 - val_loss: 0.1062\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1075 - val_loss: 0.1057\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1071 - val_loss: 0.1052\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1066 - val_loss: 0.1048\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1062 - val_loss: 0.1044\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1058 - val_loss: 0.1041\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1055 - val_loss: 0.1037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7386affd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie nous avons entrainé l'autoencoder à reconstruire des MNIST digits, on va bien que les valeurs loss pour train/test décroissent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Première ligne représentant les entrées, la deuxième ligne quand à elle représente les images reconstruites (on remarque un lègère perte de détails).\n",
    "\n",
    "### Autoencoder and sparsity :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "encoding_dim = 32\n",
    "\n",
    "input_img = Input(shape=(784,))\n",
    "# add a Dense layer with a L1 activity regularizer\n",
    "encoded = Dense(encoding_dim, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
    "# regularizers permet d'éviter l'overfitting en ajoutantla somme des poids lorsqu'on choisit L1 \n",
    "#ou leur carrés quand on choisit L2.Cost function = Loss (say, binary cross entropy) + Regularization term \n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularizers permet d'éviter l'overfitting en ajoutantla somme des poids lorsqu'on choisit L1 ou leur carrés quand on choisit L2.\n",
    "\n",
    "Cost function = Loss (say, binary cross entropy) + Regularization term \n",
    "\n",
    "Cost function = Loss + $\\lambda$ $\\sum w$, ici $\\lambda = 10e-5$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.6729 - val_loss: 0.6485\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.6284 - val_loss: 0.6090\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.5916 - val_loss: 0.5749\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5598 - val_loss: 0.5454\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.5323 - val_loss: 0.5198\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.5084 - val_loss: 0.4975\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.4875 - val_loss: 0.4780\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4692 - val_loss: 0.4609\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4531 - val_loss: 0.4457\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4389 - val_loss: 0.4324\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4262 - val_loss: 0.4205\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4150 - val_loss: 0.4098\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4049 - val_loss: 0.4003\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3959 - val_loss: 0.3918\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3877 - val_loss: 0.3840\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3804 - val_loss: 0.3771\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3737 - val_loss: 0.3707\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3676 - val_loss: 0.3649\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3621 - val_loss: 0.3596\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3570 - val_loss: 0.3548\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3524 - val_loss: 0.3503\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3481 - val_loss: 0.3463\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3442 - val_loss: 0.3425\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3406 - val_loss: 0.3390\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3372 - val_loss: 0.3357\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3341 - val_loss: 0.3327\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3312 - val_loss: 0.3299\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3285 - val_loss: 0.3273\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3259 - val_loss: 0.3249\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3236 - val_loss: 0.3226\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3213 - val_loss: 0.3204\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3193 - val_loss: 0.3184\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3173 - val_loss: 0.3165\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3155 - val_loss: 0.3147\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3138 - val_loss: 0.3131\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3121 - val_loss: 0.3115\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3106 - val_loss: 0.3100\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3091 - val_loss: 0.3085\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3077 - val_loss: 0.3072\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.3064 - val_loss: 0.3059\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3052 - val_loss: 0.3047\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3040 - val_loss: 0.3035\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3029 - val_loss: 0.3024\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3018 - val_loss: 0.3014\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.3008 - val_loss: 0.3004\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2998 - val_loss: 0.2994\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2989 - val_loss: 0.2985\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2980 - val_loss: 0.2976\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2971 - val_loss: 0.2968\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2963 - val_loss: 0.2960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff73832fe10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder et convolutions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img) \n",
    "# convolution 2D, dimension de l'espace de sortie, hateur et largeur de fenêtre de convolution,\n",
    "# avec zero padding \n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "# garder le maximum sur une fenêtre 2x2, facteur par lequel on réduit la taille de nos entrées\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "# augmente la taille des \n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
