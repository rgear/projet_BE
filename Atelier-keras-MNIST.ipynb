{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 150px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" width=400,  style=\"float:right;  display: inline\" alt=\"IMT\"/> </a>\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Ateliers: Technologies des grosses data](https://github.com/wikistat/Ateliers-Big-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Reconnaissance de caractères manuscrits](https://github.com/wikistat/Ateliers-Big-Data/2-MNIST) ([MNIST](http://yann.lecun.com/exdb/mnist/)) par apprentissage épais (*deep learning*) avec <a href=\"https://www.tensorflow.org/\"><img src=\"https://avatars0.githubusercontent.com/u/15658638?s=200&v=4\" width=100, style=\"display: inline\" alt=\"TensorFlow\"/></a> tensorflow et  <a href=\"https://keras.io/\"><img src=\"https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png\" width=250, style=\"display: inline\" alt=\"Keras\"/></a> Keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectif\n",
    "Ce calepin reprend le même objectif que les calepins de l'[Atelier MNIST](https://github.com/wikistat/Ateliers-Big-Data/tree/master/2-MNIST) et sur les mêmes données mais en utilisant cette fois les librairies `Keras` et `TensorFlow` pour aborder l'apprentissage profond. Il est une adpatation du tutoriel de Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.8 |Anaconda, Inc.| (default, Dec 29 2018, 19:04:46) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2471680169439395390\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.set()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import keras.utils as ku\n",
    "import keras.models as km\n",
    "import keras.layers as kl\n",
    "import keras.optimizers as ko\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Paramètres\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "# Vocabulary\n",
    "# One epoch is when an ENTIRE dataset is passed forward and backward through neural network only once\n",
    "# Batch_size : total number of training examples present in a single batch. \n",
    "# Batch_size : defines the number of samples to work through before updating the internal model parameters\n",
    "# Batch_size : is the number of samples processed before the model is updated. \n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "print(sys.version)\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture des données d'apprentissage et de test\n",
    "\n",
    "Les données peuvent être préalablement téléchargées ou directement lues. Ce sont celles originales du site [MNIST DataBase](http://yann.lecun.com/exdb/mnist/) mais préalablement converties au format .csv, certes plus volumineux mais plus facile à lire. Attention le fichier `mnist_train.zip` présent dans le dépôt est compressé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mnist_train.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0342f5e28191>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# path=\"\" # Si les données sont dans le répertoire courant sinon:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mDtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"mnist_train.zip\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Reprend tout le tableau sauf la dernière colonne\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    695\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    888\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mnist_train.zip'"
     ]
    }
   ],
   "source": [
    "# Lecture des données d'apprentissage\n",
    "N_classes = 10\n",
    "\n",
    "# path=\"\" # Si les données sont dans le répertoire courant sinon:\n",
    "path=\"\"\n",
    "Dtrain=pd.read_csv(path+\"mnist_train.zip\",header=None)\n",
    "\n",
    "X_train = Dtrain.values[:,:-1] # Reprend tout le tableau sauf la dernière colonne \n",
    "Y_train = Dtrain.values[:,-1] # Récupère la dernière colonne du tabelau qui correspond à ? \n",
    "\n",
    "Dtest=pd.read_csv(path+\"mnist_test.csv\",header=None)\n",
    "X_test = Dtest.values[:,:-1]\n",
    "Y_test = Dtest.values[:,-1] # label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Attention*, avec Keras, la variable réponse doit être une matrice binaire où chaque classe est représentée par une indicatrice: pour chaque individu, l'élément de la colone correspondant à la classe à laquelle il appartient est à 1, sinon il est à 0. \n",
    "\n",
    "Keras possède une fonction `to_catergorical` permettant de convertir directement le vecteur variable `Y_train` de réponse en matrice (`array numpy`) indicatrice`Y_train_cat`.\n",
    "\n",
    "C'est l'équivalent de `get_dummies` de `pandas`\n",
    " ou `OneHotEncoder` de `scikit-learn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_cat = ku.to_categorical(Y_train, N_classes) # convert a class vector to binary class matrix\n",
    "Y_test_cat = ku.to_categorical(Y_test, N_classes) # Nombre de colonne correspond au nombre de classe\n",
    "# le nombre de lignes de la matrice correspond au nombre d'éléments du vecteur original. \n",
    "# Chaque ligne corespond à un élément du vecteur initial si cet élément appartient à la j-ème classe\n",
    "# ie la j-ème colonne on met 1 le reste sera par des 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage et prévision du test Avec réseau dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Première tentative d'appliquer un réseaux de neurone de type Perceptron classique avec 4 couches: \n",
    "* Dense: 52 neurones + Foncton d'activation *relu*\n",
    "* *Dropout*: 20% des neurones tiré aléatoirement sont desactivés\n",
    "* Dense: 52 neurones + Foncton d'activation *relu*\n",
    "* *Dropout*: 20% des neurones tiré aléatoirement sont desactivés\n",
    "\n",
    "Une dernière couche *softmax* fournit la classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du réseau\n",
    "model = km.Sequential()\n",
    "model.add(kl.Dense(128, activation='relu', input_shape=(784,)))\n",
    "model.add(kl.Dropout(0.2))\n",
    "model.add(kl.Dense(128, activation='relu'))\n",
    "model.add(kl.Dropout(0.2))\n",
    "model.add(kl.Dense(N_classes, activation='softmax'))\n",
    "# Réumé\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Retrouvez manuellement le nombre de paramètres.\n",
    "\n",
    "<br>\n",
    "<font color=\"#0080FF\">\n",
    "On part d'une image de taille $28\\times 28$ dont chaque pixel est disposé selon un vecteur de $\\mathbb{R}^{784}$. On applique à ce vecteur le premier filtre, de taille 128. Ainsi, on obtient $784 \\times 128 + 128 = 100 480$ paramètres.\n",
    "\n",
    "Ensuite, on a donc un vecteur sortant du filtre 1 de taille 128, que l'on passe dans le filtre 2, ce qui donne $128 \\times 128 + 128 = 16512$ paramètres. \n",
    "\n",
    "En sortie, on remarque que la valeur souhaitée est de 10, donc on a bien $128 \\times 10 + 128 = 1290$ paramètres.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apprentissage\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=ko.RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "ts = time.time()\n",
    "history = model.fit(X_train, Y_train_cat,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test_cat))\n",
    "te = time.time()\n",
    "t_train_mpl = te-ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque : \n",
    "\n",
    "* Décroissance pour les valeurs loss et val loss tout au long des epochs \n",
    "* Croissance des valeurs acc et val_acc tout au long des epochs \n",
    "\n",
    "Ainsi on arrive à faire décroitre la fonction de perte tout au long de l'entrainement et accroitre l'exactitude de notre modèle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mpl = model.evaluate(X_test, Y_test_cat, verbose=0)\n",
    "predict_mpl = model.predict(X_test)\n",
    "print('Test loss:', score_mpl[0])\n",
    "print('Test accuracy:', score_mpl[1])\n",
    "print(\"Time Running: %.2f seconds\" %t_train_mpl )\n",
    "fig=plt.figure(figsize=(7,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax = sb.heatmap(pd.DataFrame(confusion_matrix(Y_test, predict_mpl.argmax(1))), annot=True, fmt=\"d\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Que dire de ces résultats ? \n",
    " <font color=\"#0080FF\">\n",
    "* Les résultats obtenus montrent que sur la diagonale, les valeurs sont celles qui, en moyenne, ont des valeurs importantes. Ainsi, cela montre que l'estimation du vecteur obtenu est correcte, hormis pour le caractère 4 et 6. \n",
    "\n",
    "\n",
    "* Confusion matrix  is such as C_i,j is equal to the number of observations known to be in group i but predicted to be in group j, the coefficient on the diagonal represent the  number of elements the model has managed to predict exactly. \n",
    "\n",
    "* On remarque que le modèle n'arrive pas à prédire proprement les éléments apparetenant à la classe 7. </font>\n",
    "\n",
    "**Q** Faites tourner de nouveaux l'algorithme en normalisant les données afin que celles-ci soit comprises entre 0 et 1. Qu'observez vous?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layers\n",
    "\n",
    "#### Format des données\n",
    "\n",
    "Dans les exemples précédents. Les données était \"applaties\". Une imade de $28\\times 28=784$ pixels est considérée comme un vecteur. \n",
    "\n",
    "Pour pouvoir utiliser le principe de la convolution la structure des images est conservée. Une image n'est pas un vecteur de tailles $784\\times 1$ mais une matrice de taille $28\\times 28$. Une troisième dimension est également nécessaire pour décrire afin de prendre en compte les différents `channels` de l'image. Dans le cas de `MNIST` cette dernière dimension est de taille 1 car les pixels ne sont décrits qu'avec un seul niveau de gris. Cependant, des images couleurs en RGB sont généralement codées avec trois niveaux d'intensité (Rouge, Vert et Bleus).\n",
    "\n",
    "\n",
    "Ainsi `X_train` est réorganisée en cube ou multitableau de dimensions $60000\\times 28\\times 28\\times 1$ pour être utilisé dans un réseau de convolution avec `Keras`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_conv = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test_conv = X_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.preprocessing.image as kpi\n",
    "fig  = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "x = kpi.img_to_array(X_train_conv[0])\n",
    "ax.imshow(x[:,:,0]/255, interpolation='nearest', cmap=\"binary\")\n",
    "ax.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge detection\n",
    "\n",
    "Dans cette partie vous pouvez explorer l'effet de filtre de convolution simple sur une image.\n",
    "\n",
    "Un réseau de neuronne constitué d'une couche de convolution constitué d'un seul filtre définie manuellement (non appris par optimisation) est définie dans le code ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "conv_filter = np.array([\n",
    "        [0.2, -0.2, 0],\n",
    "        [0.2, -0.2, 0],\n",
    "        [0.2, -0.2, 0],\n",
    "    ])\n",
    "\n",
    "def my_init_filter(shape, conv_filter = conv_filter, dtype=None):\n",
    "    xf,yf = conv_filter.shape\n",
    "    array = conv_filter.reshape(xf, yf, 1, 1)\n",
    "    return array\n",
    "my_init_filter(0).shape\n",
    "\n",
    "conv_edge = Sequential([\n",
    "    Conv2D(kernel_size=(3,3), filters=1, kernel_initializer=my_init_filter, input_shape=(28, 28, 1))   \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Notez que dans la fonction `my_init_filter` les dimensions de l'image sont modifiés. A quoi correspondent les deux dimensions ajoutées?\n",
    "\n",
    "* <font color=\"#0080FF\">La première dimension ajoutée correspond aux filtres de la couleur.</font>\n",
    "\n",
    "* La deuxième dimension correspond à la taille du batch, ici on traite une image à chaque fois. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_in = np.expand_dims(x, 0)\n",
    "img_out = conv_edge.predict(img_in)\n",
    "\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "ax0.imshow(img_in[0,:,:,0], cmap=\"binary\")\n",
    "ax0.set_title(\"Image originale\")\n",
    "ax0.grid(False)\n",
    "\n",
    "norm_conv_filter = (conv_filter-conv_filter.min())/conv_filter.max()\n",
    "ax1.imshow(norm_conv_filter.astype(np.uint8), cmap=\"binary\")\n",
    "ax1.set_title(\"Filtre\")\n",
    "ax1.grid(False)\n",
    "\n",
    "ax2.imshow(img_out[0,:,:,0].astype(np.uint8), cmap=\"binary\")\n",
    "ax2.set_title(\"Image Filtre\")\n",
    "ax2.grid(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Que constatez vous? Verifiez que les dimensions de l'image en sortie sont cohérentes.\n",
    "\n",
    "<font color=\"#0080FF\">On constate que l'image obtenue en sortie met en avant les zones de l'image initiale qui présentent des niveaux de gris différents selon l'axe vertical.</font>\n",
    "\n",
    "**Q** Testez ce même code avec un filtre différent.\n",
    "\n",
    "<font color=\"#0080FF\">On peut aussi utiliser un filtre différent, l'inverse du filtre précédent, c'est à dire suivant l'axe horizontal, pour analyser les résultats complémentaires. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_filter = np.array([\n",
    "        [0.2, 0.2, 0.2],\n",
    "        [-0.2, -0.2, -0.2],\n",
    "        [0, 0, 0],\n",
    "    ])\n",
    "\n",
    "def my_init_filter(shape, conv_filter = conv_filter, dtype=None):\n",
    "    xf,yf = conv_filter.shape\n",
    "    array = conv_filter.reshape(xf, yf, 1, 1)\n",
    "    return array\n",
    "my_init_filter(0).shape\n",
    "\n",
    "conv_edge = Sequential([\n",
    "    Conv2D(kernel_size=(3,3), filters=1, kernel_initializer=my_init_filter, input_shape=(28, 28, 1))   \n",
    "])\n",
    "\n",
    "img_in = np.expand_dims(x, 0)\n",
    "img_out = conv_edge.predict(img_in)\n",
    "\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "ax0.imshow(img_in[0,:,:,0], cmap=\"binary\")\n",
    "ax0.set_title(\"Image originale\")\n",
    "ax0.grid(False)\n",
    "\n",
    "norm_conv_filter = (conv_filter-conv_filter.min())/conv_filter.max()\n",
    "ax1.imshow(norm_conv_filter.astype(np.uint8), cmap=\"binary\")\n",
    "ax1.set_title(\"Filtre\")\n",
    "ax1.grid(False)\n",
    "\n",
    "ax2.imshow(img_out[0,:,:,0].astype(np.uint8), cmap=\"binary\")\n",
    "ax2.set_title(\"Image Filtre\")\n",
    "ax2.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strides and Padding\n",
    "\n",
    "Dans cette partie vous pouvez explorer l'effet des arguments `strides`et `padding` sur une image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "conv_filter = np.array([\n",
    "        [0, 0, 0],\n",
    "        [0, 1, 0],\n",
    "        [0, 0, 0],\n",
    "    ])\n",
    "\n",
    "def my_init_filter(shape, conv_filter = conv_filter, dtype=None):\n",
    "    xf,yf = conv_filter.shape\n",
    "    array = conv_filter.reshape(xf, yf, 1, 1)\n",
    "    return array\n",
    "my_init_filter(0).shape\n",
    "\n",
    "conv_sp = Sequential([\n",
    "    Conv2D(kernel_size=(3,3), filters=1, kernel_initializer=my_init_filter, input_shape=(28, 28, 1),\n",
    "           strides=2,\n",
    "           padding=\"SAME\") ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quel est l'effet du filtre défini ici? \n",
    "\n",
    "<font color=\"#0080FF\">Le filtre a ici un effet de grossissement de l'image, ce qui permet de résuire les dimensions tout en conservant l'aspect général de l'image de base.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_in = np.expand_dims(x, 0)\n",
    "img_out = conv_sp.predict(img_in)\n",
    "\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "ax0.imshow(img_in[0,:,:,0].astype(np.uint8),\n",
    "           cmap=\"binary\");\n",
    "ax0.grid(False)\n",
    "\n",
    "norm_conv_filter = (conv_filter-conv_filter.min())/conv_filter.max()\n",
    "ax1.imshow(norm_conv_filter.astype(np.uint8),\n",
    "           cmap=\"binary\");\n",
    "ax1.grid(False)\n",
    "\n",
    "ax2.imshow(img_out[0,:,:,0].astype(np.uint8),\n",
    "           cmap=\"binary\");\n",
    "ax2.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Modifiez les paramètres `stride`et `padding`, et observez l'effet sur la dimension des images. \n",
    "\n",
    "<font color=\"#0080FF\">Lorsque l'on modifie le nombre de strides, on augmente le grossissement de l'image : en effet, si le stride est égal à 1, l'image reste inchangée mais elle peut perdre en dimension, cela dépend du padding. Si on utilise un stride égal à 2, les dimensions de l'image sont alors égale à $24/2 = 12$ et si le stride est égal à 3, on a une image en sortie de taille $24/3 = 8$.</font>\n",
    "\n",
    "<font color=\"#0080FF\">Ensuite, le padding lui permet de rajouter ou non une bordure de $0$, pour ne pas perdre en dimension. En effet, si le padding est égal à 1, alors une bordure de 0 est ajoutée.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Ecrivez un code similaire pour observez l'effet du MaxPooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load max_pooling.py\n",
    "from keras.layers import MaxPool2D\n",
    "conv_mp = Sequential([ MaxPool2D(pool_size=(2,2))])\n",
    "\n",
    "img_in = np.expand_dims(x, 0)\n",
    "img_out = conv_mp.predict(img_in)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "ax0.imshow(img_in[0,:,:,0].astype(np.uint8),\n",
    "           cmap=\"binary\");\n",
    "ax0.grid(False)\n",
    "\n",
    "ax1.imshow(img_out[0,:,:,0].astype(np.uint8),\n",
    "           cmap=\"binary\");\n",
    "ax1.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Convolutional Network (ConvNet)*\n",
    "Les propriété d'invariance par translation introduites par les couches opérant une convolution des images ont un impact important sur la qualité des résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet5\n",
    "\n",
    "On teste dans un premier temps le modèle LeNet5 proposer par LeCun et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet5model = km.Sequential()\n",
    "LeNet5model.add(kl.Conv2D(filters = 6, kernel_size = 5, strides = 1, activation = 'tanh',\n",
    "input_shape = (28,28,1)))\n",
    "LeNet5model.add(kl.MaxPooling2D(pool_size = 2, strides = 2))\n",
    "LeNet5model.add(kl.Conv2D(filters = 16, kernel_size = 5,strides = 1, activation = 'tanh'))\n",
    "LeNet5model.add(kl.MaxPooling2D(pool_size = 2, strides = 2))\n",
    "LeNet5model.add(kl.Flatten())\n",
    "LeNet5model.add(kl.Dense(units = 120, activation = 'tanh'))\n",
    "LeNet5model.add(kl.Dense(units = 84, activation = 'tanh'))\n",
    "LeNet5model.add(kl.Dense(units = 10, activation = 'softmax'))\n",
    "\n",
    "LeNet5model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Retrouvez manuellement le nombre de paramètres.\n",
    "\n",
    "* Conv layers formula : $$\\text{numbers of parameters} = \\text{output_channels} \\cdot (\\text{input_channels} \\cdot \\text{Window_size} + 1)$$\n",
    "\n",
    "\n",
    "\n",
    "* Dense layers formula : $$ \\text{numbers of parameters} = \\text{output_size} \\cdot (\\text{input_size} + 1)$$\n",
    "\n",
    "\n",
    "* First layer, (conv layers), Param = 6 x ( 1 x (5 x 5) + 1) = 156\n",
    "\n",
    "\n",
    "\n",
    "* The second layer,(conv layers), Param =  16 x ( 6 x (5 x 5) + 1)= 2416\n",
    "\n",
    "\n",
    "\n",
    "* The third layer, (dense layer), Param = 120 x (256 + 1)= 30840\n",
    "\n",
    "\n",
    "\n",
    "* The fourth layer, (dense layer), Param = 84 x (120 + 1) = 10164\n",
    "\n",
    "\n",
    "\n",
    "* The fifth layer, (dense layer), Param =  10 x (84 + 1) = 850\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Q** Que dire du nombre de paramètres de ce réseau par rapport au réseau dense précédement défini?\n",
    "\n",
    "* On se retrouve avec beaucoup moins de paramètres que le réseau défini précédemment malgré qu'on ait plus  de couches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apprentissage\n",
    "LeNet5model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=ko.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "ts=time.time()\n",
    "LeNet5model.fit(X_train_conv, Y_train_cat,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_conv, Y_test_cat))\n",
    "te=time.time()\n",
    "t_train_conv = te-ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Que dire du temps de calcul? Pourquoi est-il plus long que le réseau Dense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_conv = LeNet5model.evaluate(X_test_conv, Y_test_cat, verbose=0)\n",
    "predict_conv = LeNet5model.predict(X_test_conv)\n",
    "print('Test loss:', score_conv[0])\n",
    "print('Test accuracy:', score_conv[1])\n",
    "print(\"Time Running: %.2f seconds\" %t_train_conv )\n",
    "\n",
    "fig=plt.figure(figsize=(7,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax = sb.heatmap(pd.DataFrame(confusion_matrix(Y_test, predict_conv.argmax(1))), annot=True, fmt=\"d\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autre architecture\n",
    "\n",
    "#### Réseau\n",
    "Test d'un réseau de convolution constitué de 7 couches: \n",
    "\n",
    "* Une couche de convolution 2D, avec fenêtre de taille 3x3 et une fonction d'activation *relu*\n",
    "* Une couche de convolution 2D, avec fenêtre de taille 3x3 et une fonction d'activation *relu*\n",
    "* Une couche max pooling de fenêtre 2x2\n",
    "* Une couche *dropout* où 25% des neurones sont desactivés\n",
    "* Une couche *Flatten* transforme les images $N \\times N$ en vecteurs $N^2$.\n",
    "* Une couche classique de 128 neurones\n",
    "* Une couche dropout ou 50% des neurones sont desactivés\n",
    "\n",
    "Une couche *softmax* fournit la classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descrition du réseau\n",
    "model = km.Sequential()\n",
    "model.add(kl.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28,28, 1), data_format=\"channels_last\"))\n",
    "model.add(kl.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(kl.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(kl.Dropout(0.25))\n",
    "model.add(kl.Flatten())\n",
    "model.add(kl.Dense(128, activation='relu'))\n",
    "model.add(kl.Dropout(0.5))\n",
    "model.add(kl.Dense(N_classes, activation='softmax'))\n",
    "# Résumé\n",
    "model.summary()\n",
    "# Apprentissage\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=ko.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "ts=time.time()\n",
    "model.fit(X_train_conv, Y_train_cat,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_conv, Y_test_cat))\n",
    "te=time.time()\n",
    "t_train_conv = te-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_conv = model.evaluate(X_test_conv, Y_test_cat, verbose=0)\n",
    "predict_conv = model.predict(X_test_conv)\n",
    "print('Test loss:', score_conv[0])\n",
    "print('Test accuracy:', score_conv[1])\n",
    "print(\"Time Running: %.2f seconds\" %t_train_conv )\n",
    "\n",
    "fig=plt.figure(figsize=(7,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax = sb.heatmap(pd.DataFrame(confusion_matrix(Y_test, predict_conv.argmax(1))), annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Commenter les résultats. Comparer avec les autres techniques d'apprentissage.\n",
    "\n",
    "**Paramètres**\n",
    "\n",
    "* Conv layers formula : $$\\text{numbers of parameters} = \\text{output_channels} \\cdot (\\text{input_channels} \\cdot \\text{Window_size} + 1)$$\n",
    "\n",
    "\n",
    "\n",
    "* Dense layers formula : $$ \\text{numbers of parameters} = \\text{output_size} \\cdot (\\text{input_size} + 1)$$\n",
    "\n",
    "\n",
    "* First layer, (conv layers), Param = 32 x ( 1 x (3 x 3) + 1) = 320\n",
    "\n",
    "\n",
    "\n",
    "* The second layer,(conv layers), Param =  64 x ( 32 x (3 x 3) + 1)= 18 496\n",
    "\n",
    "\n",
    "\n",
    "* The third layer, (dense layer), Param = 128 x (9216 + 1)= 1 179 776\n",
    "\n",
    "\n",
    "\n",
    "* The fourth layer, (dense layer), Param = 10 x (128 + 1) = 1 290\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "**Q** Comment améliorer encore ces résultats?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
