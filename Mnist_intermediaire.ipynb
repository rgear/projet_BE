{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/insa/anaconda/envs/GPU/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5 |Anaconda custom (64-bit)| (default, Apr 29 2018, 16:14:56) \n",
      "[GCC 7.2.0]\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12254480463671032656\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 363069440\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2470684261937581206\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.set()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import keras.utils as ku\n",
    "import keras.models as km\n",
    "import keras.layers as kl\n",
    "import keras.optimizers as ko\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Paramètres\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "# Vocabulary\n",
    "# One epoch is when an ENTIRE dataset is passed forward and backward through neural network only once\n",
    "# Batch_size : total number of training examples present in a single batch. \n",
    "# Batch_size : defines the number of samples to work through before updating the internal model parameters\n",
    "# Batch_size : is the number of samples processed before the model is updated. \n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "print(sys.version)\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture des données d'apprentissage et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture des données d'apprentissage\n",
    "N_classes = 10\n",
    "\n",
    "# path=\"\" # Si les données sont dans le répertoire courant sinon:\n",
    "path=\"\"\n",
    "Dtrain=pd.read_csv(path+\"mnist_train.zip\",header=None)\n",
    "\n",
    "X_train = Dtrain.values[:,:-1] # Reprend tout le tableau sauf la dernière colonne \n",
    "Y_train = Dtrain.values[:,-1] # Récupère la dernière colonne du tabelau qui correspond à ? \n",
    "\n",
    "Dtest=pd.read_csv(path+\"mnist_test.csv\",header=None)\n",
    "X_test = Dtest.values[:,:-1]\n",
    "Y_test = Dtest.values[:,-1] # label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_cat = ku.to_categorical(Y_train, N_classes) # convert a class vector to binary class matrix\n",
    "Y_test_cat = ku.to_categorical(Y_test, N_classes) # Nombre de colonne correspond au nombre de classe\n",
    "# le nombre de lignes de la matrice correspond au nombre d'éléments du vecteur original. \n",
    "# Chaque ligne corespond à un élément du vecteur initial si cet élément appartient à la j-ème classe\n",
    "# ie la j-ème colonne on met 1 le reste sera par des 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_conv = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test_conv = X_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etude des sorties de chaque couche "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle sans décomposition des couches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# descrition du réseau\n",
    "model = km.Sequential()\n",
    "model.add(kl.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28,28, 1), data_format=\"channels_last\"))\n",
    "model.add(kl.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(kl.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(kl.Dropout(0.25))\n",
    "model.add(kl.Flatten())\n",
    "model.add(kl.Dense(128, activation='relu'))\n",
    "model.add(kl.Dropout(0.5))\n",
    "model.add(kl.Dense(N_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "# Résumé\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.9310 - acc: 0.8832 - val_loss: 0.0613 - val_acc: 0.9810\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1085 - acc: 0.9689 - val_loss: 0.0488 - val_acc: 0.9837\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0831 - acc: 0.9762 - val_loss: 0.0449 - val_acc: 0.9850\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0655 - acc: 0.9808 - val_loss: 0.0429 - val_acc: 0.9880\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.0545 - acc: 0.9839 - val_loss: 0.0405 - val_acc: 0.9863\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0458 - acc: 0.9860 - val_loss: 0.0395 - val_acc: 0.9881\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0426 - acc: 0.9876 - val_loss: 0.0395 - val_acc: 0.9881\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0376 - acc: 0.9888 - val_loss: 0.0475 - val_acc: 0.9865\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0340 - acc: 0.9895 - val_loss: 0.0444 - val_acc: 0.9885\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0331 - acc: 0.9902 - val_loss: 0.0417 - val_acc: 0.9886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62f414e7b8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apprentissage\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=ko.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_conv, Y_train_cat,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_conv, Y_test_cat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_imgs = model.predict(X_test_conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test_conv[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(model_imgs[i].reshape(2, 5))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle avec décomposition des couches  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2D1 (Sequential)         (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2D2 (Sequential)         (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "Maxpool (Sequential)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense1 (Sequential)          (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense2 (Sequential)          (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Conv2D_1 = km.Sequential(name=\"conv2D1\")\n",
    "Conv2D_1.add(kl.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28,28, 1), data_format=\"channels_last\",name = \"conv2D1\"))\n",
    "\n",
    "Conv2D_2 = km.Sequential(name=\"conv2D2\")\n",
    "Conv2D_2.add(kl.Conv2D(64, (3, 3), activation='relu',name =\"conv2D2\"))\n",
    "\n",
    "Maxpool = km.Sequential(name=\"Maxpool\")\n",
    "Maxpool.add(kl.MaxPooling2D(pool_size=(2, 2), name =\"Maxpool\"))\n",
    "\n",
    "Dense1 = km.Sequential(name = \"dense1\")\n",
    "Dense1.add(kl.Dense(128, activation='relu',name =\"dense1\"))\n",
    "\n",
    "Dense2 = km.Sequential(name =\"dense2\")\n",
    "Dense2.add(kl.Dense(N_classes, activation='softmax',name =\"dense2\"))\n",
    "\n",
    "\n",
    "modeldecomp = km.Sequential(name=\"modèle décomposé\")\n",
    "modeldecomp.add(Conv2D_1)\n",
    "modeldecomp.add(Conv2D_2)\n",
    "modeldecomp.add(Maxpool)\n",
    "modeldecomp.add(kl.Dropout(0.25))\n",
    "modeldecomp.add(kl.Flatten())\n",
    "modeldecomp.add(Dense1)\n",
    "modeldecomp.add(kl.Dropout(0.5))\n",
    "modeldecomp.add(Dense2)\n",
    "\n",
    "modeldecomp.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 1.1032 - acc: 0.8773 - val_loss: 0.0658 - val_acc: 0.9786\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1126 - acc: 0.9673 - val_loss: 0.0592 - val_acc: 0.9835\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0858 - acc: 0.9754 - val_loss: 0.0506 - val_acc: 0.9828\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.0666 - acc: 0.9803 - val_loss: 0.0419 - val_acc: 0.9881\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.0592 - acc: 0.9832 - val_loss: 0.0379 - val_acc: 0.9894\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.0509 - acc: 0.9855 - val_loss: 0.0412 - val_acc: 0.9880\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0438 - acc: 0.9869 - val_loss: 0.0329 - val_acc: 0.9902\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.0408 - acc: 0.9880 - val_loss: 0.0368 - val_acc: 0.9892\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.0381 - acc: 0.9888 - val_loss: 0.0447 - val_acc: 0.9887\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.0342 - acc: 0.9899 - val_loss: 0.0360 - val_acc: 0.9892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62ec2dd320>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldecomp.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=ko.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "modeldecomp.fit(X_train_conv, Y_train_cat,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_conv, Y_test_cat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldecomp_imgs = modeldecomp.predict(X_test_conv)\n",
    "Conv2D_1_imgs =Conv2D_1.predict(X_test_conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 1, 32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conv2D_1.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(Conv2D_1_imgs[:,:,:,10]==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20, 4))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow(Conv2D_1_imgs[0,:,:,9])\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2D2_input to have shape (26, 26, 32) but got array with shape (28, 28, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-fc555cd0d1d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mConv2D_2_imgs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mConv2D_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_conv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mMaxpool_imgs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mMaxpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_conv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mDense1_imgs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mDense1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_conv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mDense1_imgs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mDense1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_conv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/insa/anaconda/envs/GPU/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                              'argument.')\n\u001b[1;32m   1146\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/insa/anaconda/envs/GPU/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/insa/anaconda/envs/GPU/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    135\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2D2_input to have shape (26, 26, 32) but got array with shape (28, 28, 1)"
     ]
    }
   ],
   "source": [
    "Conv2D_2_imgs =Conv2D_2.predict(Conv2D_1_imgs)\n",
    "Maxpool_imgs =Maxpool.predict(Conv2D_2_imgs)\n",
    "Dense1_imgs =Dense1.predict(X_test_conv)\n",
    "Dense1_imgs =Dense1.predict(X_test_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_imgs = model.predict(X_test_conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(6, n, i + 1)\n",
    "    plt.imshow(X_test_conv[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display output first layer Conv2D\n",
    "    ax = plt.subplot(6, n, i + 1)\n",
    "    plt.imshow(Conv2D_1_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "\n",
    "    # display output second layer Conv2D\n",
    "    ax = plt.subplot(6, n, i + 1 + n)\n",
    "    plt.imshow(Conv2D_2_imgs[i].reshape(2, 5))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display output  layer Maxpool\n",
    "    ax = plt.subplot(6, n, i + 1 + 2*n)\n",
    "    plt.imshow(Maxpool_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display output first layer Dense\n",
    "    ax = plt.subplot(6, n, i + 1 + 3*n)\n",
    "    plt.imshow(Dense1_imgs[i].reshape(2, 5))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display output last layer Dense\n",
    "    ax = plt.subplot(6, n, i + 1 + 4*n )\n",
    "    plt.imshow(Dense2_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
