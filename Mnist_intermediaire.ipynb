{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5 |Anaconda, Inc.| (default, Apr 26 2018, 08:42:37) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2019358369773089747\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.set()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import keras.utils as ku\n",
    "import keras.models as km\n",
    "import keras.layers as kl\n",
    "import keras.optimizers as ko\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Paramètres\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "# Vocabulary\n",
    "# One epoch is when an ENTIRE dataset is passed forward and backward through neural network only once\n",
    "# Batch_size : total number of training examples present in a single batch. \n",
    "# Batch_size : defines the number of samples to work through before updating the internal model parameters\n",
    "# Batch_size : is the number of samples processed before the model is updated. \n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "print(sys.version)\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture des données d'apprentissage et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture des données d'apprentissage\n",
    "N_classes = 10\n",
    "\n",
    "# path=\"\" # Si les données sont dans le répertoire courant sinon:\n",
    "path=\"\"\n",
    "Dtrain=pd.read_csv(path+\"mnist_train.zip\",header=None)\n",
    "\n",
    "X_train = Dtrain.values[:,:-1] # Reprend tout le tableau sauf la dernière colonne \n",
    "Y_train = Dtrain.values[:,-1] # Récupère la dernière colonne du tabelau qui correspond à ? \n",
    "\n",
    "Dtest=pd.read_csv(path+\"mnist_test.csv\",header=None)\n",
    "X_test = Dtest.values[:,:-1]\n",
    "Y_test = Dtest.values[:,-1] # label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_cat = ku.to_categorical(Y_train, N_classes) # convert a class vector to binary class matrix\n",
    "Y_test_cat = ku.to_categorical(Y_test, N_classes) # Nombre de colonne correspond au nombre de classe\n",
    "# le nombre de lignes de la matrice correspond au nombre d'éléments du vecteur original. \n",
    "# Chaque ligne corespond à un élément du vecteur initial si cet élément appartient à la j-ème classe\n",
    "# ie la j-ème colonne on met 1 le reste sera par des 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_conv = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test_conv = X_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etude des sorties de chaque couche "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle sans décomposition des couches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# descrition du réseau\n",
    "model = km.Sequential()\n",
    "model.add(kl.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28,28, 1), data_format=\"channels_last\"))\n",
    "model.add(kl.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(kl.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(kl.Dropout(0.25))\n",
    "model.add(kl.Flatten())\n",
    "model.add(kl.Dense(128, activation='relu'))\n",
    "model.add(kl.Dropout(0.5))\n",
    "model.add(kl.Dense(N_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "# Résumé\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 1.1393 - acc: 0.8723 - val_loss: 0.0577 - val_acc: 0.9798\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 99s 2ms/step - loss: 0.1061 - acc: 0.9698 - val_loss: 0.0396 - val_acc: 0.9878\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.0765 - acc: 0.9776 - val_loss: 0.0351 - val_acc: 0.9889\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 98s 2ms/step - loss: 0.0621 - acc: 0.9818 - val_loss: 0.0359 - val_acc: 0.9895\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 98s 2ms/step - loss: 0.0530 - acc: 0.9848 - val_loss: 0.0317 - val_acc: 0.9904\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 98s 2ms/step - loss: 0.0442 - acc: 0.9871 - val_loss: 0.0383 - val_acc: 0.9894\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.0408 - acc: 0.9876 - val_loss: 0.0348 - val_acc: 0.9905\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.0389 - acc: 0.9888 - val_loss: 0.0337 - val_acc: 0.9906\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.0339 - acc: 0.9894 - val_loss: 0.0327 - val_acc: 0.9910\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.0313 - acc: 0.9908 - val_loss: 0.0322 - val_acc: 0.9909\n"
     ]
    }
   ],
   "source": [
    "# Apprentissage\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=ko.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "ts=time.time()\n",
    "model.fit(X_train_conv, Y_train_cat,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_conv, Y_test_cat))\n",
    "te=time.time()\n",
    "t_train_conv = te-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_imgs = model.predict(X_test_conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test_conv[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(model_imgs[i].reshape(2, 5))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle avec décomposition des couches  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv2D_1 = km.Sequential(name=\"conv2D1\")\n",
    "Conv2D_1.add(kl.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28,28, 1), data_format=\"channels_last\",name = \"conv2D1\"))\n",
    "\n",
    "Conv2D_2 = km.Sequential(name=\"conv2D2\")\n",
    "Conv2D_2.add(kl.Conv2D(64, (3, 3), activation='relu',name =\"conv2D2\"))\n",
    "\n",
    "Maxpool = km.Sequential(name=\"Maxpool\")\n",
    "Maxpool.add(kl.MaxPooling2D(pool_size=(2, 2), name =\"Maxpool\"))\n",
    "\n",
    "Dense1 = km.Sequential(name = \"dense1\")\n",
    "Dense1.add(kl.Dense(128, activation='relu',name =\"dense1\"))\n",
    "\n",
    "Dense2 = km.Sequential(name =\"dense2\")\n",
    "Dense2.add(kl.Dense(N_classes, activation='softmax',name =\"dense2\"))\n",
    "\n",
    "\n",
    "modeldecomp = km.Sequential(name=\"modèle décomposé\")\n",
    "modeldecomp.add(Conv2D_1)\n",
    "modeldecomp.add(Conv2D_2)\n",
    "modeldecomp.add(Maxpool)\n",
    "modeldecomp.add(kl.Dropout(0.25))\n",
    "modeldecomp.add(kl.Flatten())\n",
    "modeldecomp.add(Dense1)\n",
    "modeldecomp.add(kl.Dropout(0.5))\n",
    "modeldecomp.add(Dense2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldecomp.compile(loss='binary_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "modeldecomp.fit(X_train_conv, X_train_conv,\n",
    "                    batch_size=256,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test_conv,X_test_conv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldecomp_imgs = autoencoder.predict(X_test_conv)\n",
    "Conv2D_1_imgs =Conv2D_1.predict(X_test_conv)\n",
    "Conv2D_2_imgs =Conv2D_2.predict(X_test_conv)\n",
    "Maxpool_imgs =Maxpool.predict(X_test_conv)\n",
    "Dense1_imgs =Dense1.predict(X_test_conv)\n",
    "Dense1_imgs =Dense1.predict(X_test_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(6, n, i + 1)\n",
    "    plt.imshow(X_test_conv[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display output first layer Conv2D\n",
    "    ax = plt.subplot(6, n, i + 1)\n",
    "    plt.imshow(Conv2D_1_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "\n",
    "    # display output second layer Conv2D\n",
    "    ax = plt.subplot(6, n, i + 1 + n)\n",
    "    plt.imshow(Conv2D_2_imgs[i].reshape(2, 5))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display output  layer Maxpool\n",
    "    ax = plt.subplot(6, n, i + 1 + 2*n)\n",
    "    plt.imshow(Maxpool_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display output first layer Dense\n",
    "    ax = plt.subplot(6, n, i + 1 + 3*n)\n",
    "    plt.imshow(Dense1_imgs[i].reshape(2, 5))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display output last layer Dense\n",
    "    ax = plt.subplot(6, n, i + 1 + 4*n )\n",
    "    plt.imshow(Dense2_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
